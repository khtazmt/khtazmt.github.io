import subprocess
import sys
import os
from datetime import datetime, timedelta
import re
from urllib.parse import unquote

def get_git_diff(commit_range=None):
    """
    è·å–git diffçš„å†…å®¹
    
    Args:
        commit_range: å¯é€‰çš„æäº¤èŒƒå›´ï¼Œä¾‹å¦‚ 'HEAD^..HEAD'
    
    Returns:
        str: git diffçš„è¾“å‡ºå†…å®¹
    """
    try:
        if commit_range:
            cmd = ['git', 'diff', commit_range]
        else:
            # é»˜è®¤è·å–å‰ä¸€å¤©åˆ°ç°åœ¨çš„æ”¹åŠ¨
            yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
            today = datetime.now().strftime('%Y-%m-%d')
            # ä½¿ç”¨ --since å’Œ --until æ¥æŒ‡å®šæ—¶é—´èŒƒå›´
            cmd = ['git', 'log', '-p', f'--since={yesterday} 00:00:00', f'--until={today} 23:59:59']
            
        # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ç¡®ä¿ git è¾“å‡ºä½¿ç”¨ UTF-8 ç¼–ç 
        env = os.environ.copy()
        env['LANG'] = 'en_US.UTF-8'
        env['GIT_TERMINAL_PROMPT'] = '0'
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            encoding='utf-8',  # æ˜ç¡®æŒ‡å®šç¼–ç ä¸º UTF-8
            errors='replace',  # å¤„ç†æ— æ³•è§£ç çš„å­—ç¬¦
            env=env,
            check=True
        )
        
        return result.stdout
        
    except subprocess.CalledProcessError as e:
        print(f"è·å–git diffæ—¶å‘ç”Ÿé”™è¯¯: {e}", file=sys.stderr)
        return None
    except Exception as e:
        print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", file=sys.stderr)
        return None

def get_indent_level(line):
    """è·å–å†…å®¹çš„ç¼©è¿›å±‚çº§"""
    # ç§»é™¤å‰é¢çš„ "- " æˆ– "+ "
    content = re.sub(r'^[+-] ', '', line.strip())
    
    # æ£€æŸ¥åŸå§‹è¡Œçš„ç¼©è¿›
    original_indent = len(line) - len(line.lstrip())
    base_level = original_indent // 2  # æ¯ä¸¤ä¸ªç©ºæ ¼ç®—ä¸€çº§
    
    # æ£€æŸ¥å†…å®¹ä¸­çš„é¢å¤–ç¼©è¿›
    if content.startswith('- '):
        content = content[2:]
        content_indent = len(content) - len(content.lstrip())
        return base_level + (content_indent // 2) + 1
    
    return base_level + 1

def format_content_with_indent(content_list):
    """æ ¼å¼åŒ–å†…å®¹ï¼Œæ·»åŠ æ­£ç¡®çš„ logseq ç¼©è¿›"""
    formatted = []
    addition_block = []
    
    # æ„å»ºå±‚çº§ç»“æ„
    hierarchy = []
    for line in content_list:
        if not line:  # ç©ºè¡Œ
            hierarchy.append((line, 0))
            continue
            
        if line.startswith('- [[') or line.startswith('- 20'):  # æ ‡é¢˜è¡Œ
            hierarchy.append((line, 0))
            continue
        
        # è®¡ç®—ç¼©è¿›çº§åˆ«
        indent_match = re.match(r'^(\t+)- ', line)
        if indent_match:
            # ä½¿ç”¨åˆ¶è¡¨ç¬¦æ•°é‡ç¡®å®šçº§åˆ«
            level = len(indent_match.group(1))
            content = line.strip()
            hierarchy.append((content, level))
        else:
            # æ²¡æœ‰ç¼©è¿›ï¼Œé»˜è®¤ä¸ºä¸€çº§
            content = line.strip()
            hierarchy.append((content, 1))
    
    # æ ¹æ®å±‚çº§ç»“æ„ç”Ÿæˆè¾“å‡º
    previous_level = 0
    for content, level in hierarchy:
        if not content:  # ä¿ç•™ç©ºè¡Œ
            if addition_block:
                formatted.extend(addition_block)
                formatted.append('')
                addition_block = []
            formatted.append(content)
            continue
            
        # å¤„ç†æ ‡é¢˜è¡Œ
        if content.startswith('- [[') or content.startswith('- 20'):
            if addition_block:
                formatted.extend(addition_block)
                formatted.append('')
                addition_block = []
            formatted.append(content)
            previous_level = 0
            continue
            
        # è·³è¿‡è½¬ç§»å†…å®¹çš„æ ‡è®°è¡Œ
        if content.strip().startswith('ä» '):
            continue
            
        # å¤„ç†æ™®é€šå†…å®¹è¡Œ
        if content.strip():
            # ä½¿ç”¨åˆ¶è¡¨ç¬¦ç”Ÿæˆç¼©è¿›
            indent = '\t' * level
            
            # ç¡®ä¿è¡Œä»¥ "- " å¼€å¤´
            if not content.startswith('- '):
                content = '- ' + content
            
            # åªå¤„ç†æ·»åŠ çš„å†…å®¹æˆ–æ™®é€šå†…å®¹
            if '**' in content:
                content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)
                addition_block.append(indent + content)
            elif '~~' not in content:
                formatted.append(indent + content)
                previous_level = level
    
    # å¤„ç†æœ€åçš„æ·»åŠ å—
    if addition_block:
        formatted.extend(addition_block)
    
    return formatted

def normalize_content(content):
    """æ ‡å‡†åŒ–å†…å®¹ï¼Œç§»é™¤ç¼©è¿›ã€æ¢è¡Œã€é“¾æ¥å’Œå¤šä½™ç©ºæ ¼"""
    # ç§»é™¤ markdown åˆ—è¡¨ç¬¦å·å’Œç¼©è¿›
    content = re.sub(r'^[\s-]*', '', content)
    
    # ä¿ç•™ logseq ç‰¹å®šæ ¼å¼çš„å†…å®¹
    def preserve_logseq_format(match):
        return f" {match.group(0)} "  # åœ¨ç‰¹æ®Šæ ¼å¼å‰åæ·»åŠ ç©ºæ ¼
    
    # å¤„ç† logseq ç‰¹æ®Šæ ¼å¼
    content = re.sub(r'\(\([^)]+\)\)', preserve_logseq_format, content)  # å¼•ç”¨æ ¼å¼ ((id))
    content = re.sub(r'\[\[[^\]]+\]\]', preserve_logseq_format, content)  # é¡µé¢é“¾æ¥ [[page]]
    content = re.sub(r'TODO|DOING|DONE|NOW|LATER|WAITING|CANCELED', preserve_logseq_format, content)  # ä»»åŠ¡çŠ¶æ€
    
    # ç§»é™¤ markdown é“¾æ¥æ ¼å¼ [text](url)ï¼Œä½†ä¿ç•™æ–‡æœ¬
    content = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', content)
    
    # ç§»é™¤ HTML é“¾æ¥
    content = re.sub(r'<[^>]+>', '', content)
    
    # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
    content = ' '.join(content.split())
    return content

def has_real_content(content_list, ignore_patterns):
    """æ£€æŸ¥æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼ˆä¸åŒ…æ‹¬æ ‡é¢˜ã€ç©ºè¡Œå’Œç»“æ„å˜åŒ–ï¼‰"""
    if len(content_list) <= 1:  # åªæœ‰æ ‡é¢˜æˆ–ç©º
        return False
    
    has_meaningful_change = False
    previous_content = None
    deletion_count = 0
    
    for line in content_list[1:]:  # è·³è¿‡æ ‡é¢˜
        if line and not line.isspace() and not line.startswith('ä» '):
            content = line.strip('- ').strip()
            if content and not any(pattern in content for pattern in ignore_patterns):
                # æ ‡å‡†åŒ–å½“å‰å†…å®¹
                normalized = normalize_content(content)
                if not normalized:  # å¦‚æœæ ‡å‡†åŒ–åä¸ºç©ºï¼Œè¯´æ˜åªæœ‰æ ¼å¼æ²¡æœ‰å®é™…å†…å®¹
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ é™¤å†…å®¹
                if '~~' in content and '**' not in content:
                    deletion_count += 1
                    if deletion_count > 3:  # å¦‚æœè¿ç»­åˆ é™¤è¶…è¿‡3è¡Œï¼Œå¿½ç•¥è¿™ä¸ªæ–‡ä»¶
                        return False
                else:
                    deletion_count = 0
                
                # æ£€æŸ¥æ˜¯å¦åªæ˜¯ç»“æ„å˜åŒ–
                if '~~' in content or '**' in content:
                    clean_content = re.sub(r'~~.*?~~|\*\*.*?\*\*', '', content)
                    normalized_clean = normalize_content(clean_content)
                    if normalized_clean and (previous_content is None or normalized_clean != previous_content):
                        has_meaningful_change = True
                else:
                    if previous_content is None or normalized != previous_content:
                        has_meaningful_change = True
                
                previous_content = normalized
    
    return has_meaningful_change

def add_spaces_around_refs(content):
    """åœ¨å¼•ç”¨æ ¼å¼å‰åæ·»åŠ ç©ºæ ¼"""
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰å¼•ç”¨æ ¼å¼
    pattern = r'\(\([^)]+\)\)'
    parts = []
    last_end = 0
    
    for match in re.finditer(pattern, content):
        start, end = match.span()
        # æ·»åŠ å‰é¢çš„æ–‡æœ¬
        prefix = content[last_end:start].rstrip()
        parts.append(prefix)
        # æ·»åŠ å¸¦ç©ºæ ¼çš„å¼•ç”¨
        ref = match.group()
        if parts and not parts[-1].endswith(' '):  # æ£€æŸ¥åˆ—è¡¨æ˜¯å¦ä¸ºç©º
            parts[-1] += ' '
        parts.append(ref)
        last_end = end
    
    # æ·»åŠ å‰©ä½™çš„æ–‡æœ¬
    if last_end < len(content):
        remaining = content[last_end:].lstrip()
        if remaining:
            if parts and not parts[-1].endswith(' '):  # æ£€æŸ¥åˆ—è¡¨æ˜¯å¦ä¸ºç©º
                parts.append(' ')
            parts.append(remaining)
    
    # å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œç›´æ¥è¿”å›åŸå†…å®¹
    return ''.join(parts) if parts else content

def format_diff_line(old_line, new_line):
    """æ ¼å¼åŒ–å·®å¼‚è¡Œï¼Œä½¿ç”¨Markdownè¯­æ³•æ ‡è®°å˜åŒ–"""
    # å¦‚æœå†…å®¹å®Œå…¨ç›¸åŒï¼Œè¿”å›None
    if old_line == new_line:
        return None
    
    # å»æ‰è¡Œé¦–çš„ '- ' æˆ– '+ ' å¹¶å¤„ç†å¯èƒ½çš„å¤šä½™ç©ºæ ¼
    old_content = old_line[2:].strip()
    new_content = new_line[2:].strip()
    
    # å»æ‰å¯èƒ½å­˜åœ¨çš„é¢å¤– '- ' å‰ç¼€
    if old_content.startswith('- '):
        old_content = old_content[2:].strip()
    if new_content.startswith('- '):
        new_content = new_content[2:].strip()
    
    # åœ¨å¼•ç”¨æ ¼å¼å‰åæ·»åŠ ç©ºæ ¼
    old_content = add_spaces_around_refs(old_content)
    new_content = add_spaces_around_refs(new_content)
    
    # æ ‡å‡†åŒ–å¹¶æ¯”è¾ƒå†…å®¹
    old_normalized = normalize_content(old_content)
    new_normalized = normalize_content(new_content)
    if old_normalized == new_normalized:
        return None
    
    # åˆ†åˆ«è¿”å›åˆ é™¤å’Œæ·»åŠ çš„å†…å®¹
    return {
        'deleted': f"- ~~{old_content}~~",
        'added': f"- **{new_content}**"
    }

def save_diff_to_file(diff_content, output_dir="diffs"):
    """
    å°†diffå†…å®¹ä¿å­˜åˆ°æ–‡ä»¶
    
    Args:
        diff_content: diffçš„å†…å®¹
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º'diffs'
    
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        filename = "æœ€è¿‘ä¸€å¤©çš„æ–°å¢.md"
        filepath = os.path.join(output_dir, filename)
        
        # éœ€è¦å¿½ç•¥çš„æ ¼å¼
        ignore_patterns = [
            'id::',
            'collapsed::',
            'created::',
            'updated::',
        ]
        
        # ä½¿ç”¨å­—å…¸æ¥å­˜å‚¨æ¯ä¸ªæ ‡é¢˜çš„åŸå§‹å†…å®¹è¡Œ
        title_raw_contents = {}
        current_title = None
        current_content = []
        source_title = None
        deleted_content = None  # åˆå§‹åŒ– deleted_content
        is_new_file = False
        new_file_line_count = 0  # æ–°å¢æ–‡ä»¶çš„è¡Œæ•°è®¡æ•°å™¨
        last_was_addition = False  # åˆå§‹åŒ– last_was_addition
        
        for line in diff_content.splitlines():
            if line.startswith('diff --git'):
                # å¤„ç†å‰ä¸€ä¸ªæ–‡ä»¶çš„å†…å®¹
                if current_content and current_title:
                    if has_real_content(current_content, ignore_patterns):
                        # å°†åŸå§‹å†…å®¹è¡Œæ·»åŠ åˆ°å¯¹åº”æ ‡é¢˜çš„åˆ—è¡¨ä¸­
                        if current_title not in title_raw_contents:
                            title_raw_contents[current_title] = []
                        title_raw_contents[current_title].extend(current_content[1:])  # è·³è¿‡æ ‡é¢˜è¡Œ
                
                current_content = []
                is_new_file = False
                
                # æå–å¹¶å¤„ç†æ–‡ä»¶å
                match = re.search(r'b/(.+)$', line)
                if match:
                    file_path = match.group(1)
                    
                    # å¤„ç†æ–‡ä»¶è·¯å¾„
                    # 1. å¤„ç†å…«è¿›åˆ¶ç¼–ç çš„ä¸­æ–‡å­—ç¬¦
                    if '\\' in file_path:
                        try:
                            # æå–å…«è¿›åˆ¶ç¼–ç éƒ¨åˆ†ï¼ˆæ’é™¤.md"ç­‰åç¼€ï¼‰
                            encoded_parts = re.findall(r'\\([0-7]{3})', file_path)
                            if encoded_parts:
                                # å°†å…«è¿›åˆ¶è½¬æ¢ä¸ºå­—èŠ‚åºåˆ—
                                bytes_array = bytes([int(x, 8) for x in encoded_parts])
                                # å°†å­—èŠ‚åºåˆ—è§£ç ä¸ºUTF-8å­—ç¬¦ä¸²
                                decoded = bytes_array.decode('utf-8')
                                # æ›¿æ¢åŸæ–‡ä»¶åä¸­çš„å…«è¿›åˆ¶éƒ¨åˆ†
                                file_path = re.sub(r'\\[0-7]{3}', lambda _: decoded[len(re.findall(r'\\[0-7]{3}', file_path[:_.start()])):len(re.findall(r'\\[0-7]{3}', file_path[:_.end()]))], file_path)
                        except Exception as e:
                            print(f"è§£ç æ–‡ä»¶åå¤±è´¥: {e}", file=sys.stderr)
                            # è§£ç å¤±è´¥æ—¶ä¿æŒåŸæ ·
                            pass
                    elif '%' in file_path:
                        try:
                            file_path = unquote(file_path)
                        except:
                            pass
                    
                    # 2. ç§»é™¤å¸¸è§å‰ç¼€
                    title = file_path.replace('pages/', '').replace('journals/', '')
                    # 3. ç§»é™¤æ–‡ä»¶æ‰©å±•å
                    title = re.sub(r'\.md"?$', '', title)
                    # 4. ç§»é™¤æ—¥æœŸæ ¼å¼ä¸­çš„ä¸‹åˆ’çº¿
                    title = re.sub(r'(\d{4})_(\d{2})_(\d{2})', r'\1\2\3', title)
                    
                    if title:
                        current_content.append(f"- {title}")
                        current_title = title
            
            elif line.startswith('+++ b/'):
                is_new_file = True
            
            elif line.startswith(('+', '-')) and not line.startswith(('+++ ', '--- ')):
                content = line.strip()
                
                if not any(pattern in content for pattern in ignore_patterns) and len(content) > 1:
                    # å¤„ç†åˆ é™¤çš„å†…å®¹
                    if content.startswith('-'):
                        if deleted_content is None:
                            deleted_content = content
                        source_title = current_title
                        last_was_addition = False
                    # å¤„ç†æ·»åŠ çš„å†…å®¹
                    elif content.startswith('+'):
                        content_without_prefix = content[1:].strip()
                        if content_without_prefix.startswith('- '):
                            content_without_prefix = content_without_prefix[2:].strip()
                        current_content.append('- ' + content_without_prefix)
                        deleted_content = None
                        last_was_addition = True
        
        # å¤„ç†æœ€åä¸€ä¸ªæ–‡ä»¶çš„å†…å®¹
        if current_content and current_title and has_real_content(current_content, ignore_patterns):
            if current_title not in title_raw_contents:
                title_raw_contents[current_title] = []
            title_raw_contents[current_title].extend(current_content[1:])
        
        # ç”Ÿæˆæœ€ç»ˆçš„å†…å®¹
        content_files = []
        for title, raw_contents in title_raw_contents.items():
            if raw_contents:  # åªå¤„ç†æœ‰å†…å®¹çš„æ ‡é¢˜
                # æ·»åŠ æ ‡é¢˜
                content_files.append(f"- {format_page_title(title)}")
                
                # é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–å†…å®¹å¹¶ç§»é™¤å·²æœ‰ç¼©è¿›
                standardized_contents = []
                for line in raw_contents:
                    if line.strip():
                        # ç§»é™¤å·²æœ‰çš„ç¼©è¿›
                        content = line.strip()
                        if not content.startswith('- '):
                            content = '- ' + content
                        standardized_contents.append(content)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸è¿ç»­çš„å†…å®¹å—
                blocks = []
                current_block = []
                for line in standardized_contents:
                    if line.strip():
                        current_block.append(line)
                    else:
                        if current_block:
                            blocks.append(current_block)
                            current_block = []
                
                if current_block:  # æ·»åŠ æœ€åä¸€ä¸ªå—
                    blocks.append(current_block)
                
                # åˆ†åˆ«å¤„ç†æ¯ä¸ªå—ï¼Œä¿æŒç‹¬ç«‹æ€§
                all_processed = []
                for block in blocks:
                    processed = analyze_hierarchy(block)
                    all_processed.extend(processed)
                    all_processed.append('')  # å—ä¹‹é—´æ·»åŠ ç©ºè¡Œ
                
                # æ·»åŠ å¤„ç†åçš„å†…å®¹
                if all_processed:
                    content_files.extend(all_processed)
                    content_files.append('')  # æ ‡é¢˜ä¹‹é—´æ·»åŠ ç©ºè¡Œ
        
        # ç§»é™¤æœ«å°¾çš„ç©ºè¡Œ
        while content_files and not content_files[-1]:
            content_files.pop()
        
        # åªæœ‰åœ¨æœ‰å®é™…å†…å®¹æ—¶æ‰å†™å…¥æ–‡ä»¶
        if content_files:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write('\n'.join(content_files))
            return filepath
        return None
        
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}", file=sys.stderr)
        return None

def format_page_title(title):
    """æ ¼å¼åŒ–é¡µé¢æ ‡é¢˜ï¼Œæ·»åŠ  [[]] æ ‡è®°"""
    # å¦‚æœæ˜¯æ—¥æœŸæ ¼å¼ï¼Œä¸æ·»åŠ  [[]]
    if re.match(r'^\d{8}$', title):
        return title
    # å¦‚æœå·²ç»æœ‰ [[]]ï¼Œä¸é‡å¤æ·»åŠ 
    if title.startswith('[[') and title.endswith(']]'):
        return title
    # å¦‚æœæ ‡é¢˜ä¸­å·²ç»åŒ…å« [[]] æ ¼å¼çš„éƒ¨åˆ†ï¼Œä¸å¤„ç†
    if '[[' in title or ']]' in title:
        return title
    return f"[[{title}]]"

def analyze_hierarchy(raw_contents):
    """åˆ†æå†…å®¹çš„å±‚çº§å…³ç³»å¹¶æ·»åŠ æ­£ç¡®çš„ç¼©è¿›"""
    processed = []
    
    # ç®€åŒ–å¤„ç†ï¼šå¯¹äºå¤§å¤šæ•°å†…å®¹ï¼Œé»˜è®¤ä½¿ç”¨ä¸€çº§ç¼©è¿›
    # åªæœ‰æ˜ç¡®è¯†åˆ«ä¸ºåµŒå¥—å†…å®¹æ—¶æ‰ä½¿ç”¨æ›´æ·±çš„ç¼©è¿›
    for line in raw_contents:
        if not line.strip():
            continue
            
        content = line.strip()
        # ç¡®ä¿è¡Œä»¥ "- " å¼€å¤´
        if not content.startswith('- '):
            content = '- ' + content
            
        # è·³è¿‡åˆ é™¤çš„å†…å®¹
        if '~~' in content and '**' not in content:
            continue
            
        # å¤„ç†æ·»åŠ çš„å†…å®¹
        if '**' in content:
            content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¼•ç”¨å†…å®¹ï¼Œå¯èƒ½éœ€è¦é¢å¤–ç¼©è¿›
        is_quote = (content.startswith('- "') or content.startswith('- ã€Œ') or 
                   content.startswith('- #') or content.startswith('- (('))
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é“¾æ¥å†…å®¹
        is_link = ('http' in content or 'bilibili' in content or 'å“”å“©å“”å“©' in content or 
                  content.startswith('- ğŸ”—') or '[' in content and ']' in content)
        
        # é»˜è®¤ä½¿ç”¨ä¸€çº§ç¼©è¿›
        level = 1
        
        # ç‰¹æ®Šæƒ…å†µï¼šå¼•ç”¨å†…å®¹å’Œé“¾æ¥å†…å®¹å¯èƒ½æ˜¯å­é¡¹
        if is_quote and len(processed) > 0 and processed[-1].startswith('\t- '):
            # å¦‚æœå‰ä¸€é¡¹æ˜¯ä¸€çº§ç¼©è¿›ï¼Œå¹¶ä¸”å½“å‰æ˜¯å¼•ç”¨ï¼Œå¯èƒ½æ˜¯å­é¡¹
            prev_line = processed[-1].strip()
            if not (prev_line.startswith('- "') or prev_line.startswith('- ã€Œ') or 
                    prev_line.startswith('- #') or prev_line.startswith('- ((')):
                level = 2
        
        # æ·»åŠ ç¼©è¿›å¹¶ä¿å­˜
        indent = '\t' * level
        processed.append(indent + content)
    
    return processed

if __name__ == "__main__":
    # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œåˆ™ä½¿ç”¨å®ƒä½œä¸ºcommitèŒƒå›´
    commit_range = sys.argv[1] if len(sys.argv) > 1 else None
    
    diff_content = get_git_diff(commit_range)
    if diff_content:
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = save_diff_to_file(diff_content)
        if output_file:
            print(f"diffå†…å®¹å·²ä¿å­˜åˆ°: {output_file}")
        else:
            sys.exit(1)
    else:
        sys.exit(1) 